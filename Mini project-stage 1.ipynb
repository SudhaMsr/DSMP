{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08062efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fake_transactional_data_24.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f57f26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e721c9",
   "metadata": {},
   "source": [
    "# Analysing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bc716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacca82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ac082",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data set\n",
    "data = pd.read_csv('fake_transactional_data_24.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a605d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## head\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c7056d",
   "metadata": {},
   "source": [
    "## Finding missing values- EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf8ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull()  ##missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63900c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba83d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab012e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## statistical data\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea76f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1740fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381c46fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique() ##any unique values??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea13a7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26c39f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d267b19f",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7138bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(figsize=(10, 8), bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9687c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(data['from_totally_fake_account'], bins=50, kde=True)\n",
    "plt.title('Distribution of from_totally_fake_account')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(data['monopoly_money_amount'], bins=50, kde=True)\n",
    "plt.title('Distribution of monopoly_money_amount')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca09ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c596007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'not_happened_yet_date' column to datetime with 'coerce' error handling\n",
    "data['not_happened_yet_date'] = pd.to_datetime(data['not_happened_yet_date'], errors='coerce')\n",
    "\n",
    "# Time series plot\n",
    "plt.figure(figsize=(9, 6))\n",
    "data.set_index('not_happened_yet_date')['monopoly_money_amount'].plot()\n",
    "plt.title('Monopoly Money Amount Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Monopoly Money Amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5273e52",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08afc180",
   "metadata": {},
   "outputs": [],
   "source": [
    "## finding outliers\n",
    "# Box plots \n",
    "sns.boxplot(data=data, orient='h')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d50746f",
   "metadata": {},
   "source": [
    "### Finding outliers count in  ' from_totally_fake_account '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a5e4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['from_totally_fake_account'].skew           ##skew method\n",
    "## finding IQR\n",
    "percentile25= data['from_totally_fake_account'].quantile(0.25)\n",
    "percentile75= data['from_totally_fake_account'].quantile(0.75)\n",
    "percentile75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1fbbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr= percentile75-percentile25\n",
    "upperlimit=percentile75+ 1.5 *iqr\n",
    "lowerlimit= percentile75 - 1.5 *iqr\n",
    "print(\"Upper limit\", upperlimit)\n",
    "print(\"Lower limit\", lowerlimit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbd4953",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_count_from_account = len(data[(data['from_totally_fake_account'] < lowerlimit) | (data['from_totally_fake_account'] > upperlimit)])\n",
    "print(\"Outliers in 'from_totally_fake_account':\", outliers_count_from_account)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5263fb9e",
   "metadata": {},
   "source": [
    "### Finding outliers count in  ' monopoly_money_amount '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e170935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['monopoly_money_amount'].skew           ##skew method\n",
    "## finding IQR\n",
    "percentile25= data['monopoly_money_amount'].quantile(0.25)\n",
    "percentile75= data['monopoly_money_amount'].quantile(0.75)\n",
    "percentile75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa69589",
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr= percentile75-percentile25\n",
    "upperlimit=percentile75+ 1.5 *iqr\n",
    "lowerlimit= percentile75 - 1.5 *iqr\n",
    "print(\"Upper limit\", upperlimit)\n",
    "print(\"Lower limit\", lowerlimit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e0ed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_count_monopoly_amount = len(data[(data['monopoly_money_amount'] < lowerlimit) | (data['monopoly_money_amount'] > upperlimit)])\n",
    "print(\"Outliers count in 'monopoly_money_amount':\", outliers_count_monopoly_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df49a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0150baa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data = data.select_dtypes(include=[np.number])\n",
    "corr_matrix = numeric_data.corr()\n",
    "sns.heatmap(corr_matrix, annot=True)\n",
    "plt.show()\n",
    "##, cmap='coolwarm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4259e18c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68fdd6a6",
   "metadata": {},
   "source": [
    "# Identify patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92de91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identify Frequency and Patterns in Transaction Amount\n",
    "\n",
    "# Calculate the frequency of transactions for each customer\n",
    "transaction_frequency = data['from_totally_fake_account'].value_counts()\n",
    "\n",
    "# Visualize transaction frequency\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(transaction_frequency, bins=50, kde=True)\n",
    "plt.title('Transaction Frequency Distribution')\n",
    "plt.xlabel('Number of Transactions')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff8215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053a0360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze transaction amounts to identify patterns\n",
    "# Consider statistical measures\n",
    "mean_transaction_amount = data['monopoly_money_amount'].mean()\n",
    "median_transaction_amount = data['monopoly_money_amount'].median()\n",
    "\n",
    "# Visualization tools\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['monopoly_money_amount'], bins=50, kde=True)\n",
    "plt.title('Distribution of Monopoly Money Amount')\n",
    "plt.xlabel('Monopoly Money Amount')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Box plot to identify patterns and outliers\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x=data['monopoly_money_amount'])\n",
    "plt.title('Boxplot of Monopoly Money Amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f042e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8a53f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526010fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b7b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    kmeans.fit(data[['monopoly_money_amount']])\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('Elbow Method for Optimal Clusters')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b9bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Feature scaling for better clustering results\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data[['monopoly_money_amount']])\n",
    "\n",
    "# Determine the optimal number of clusters using the elbow method\n",
    "def determine_optimal_k(data):\n",
    "    distortions = []\n",
    "    K_range = range(1, 11)  # You can adjust the range based on your dataset and requirements\n",
    "    \n",
    "    for k in K_range:\n",
    "        kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "        kmeans.fit(data)\n",
    "        distortions.append(kmeans.inertia_)\n",
    "\n",
    "    # Plotting the elbow graph\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(K_range, distortions, marker='o')\n",
    "    plt.title('Elbow Method for Optimal k')\n",
    "    plt.xlabel('Number of Clusters (k)')\n",
    "    plt.ylabel('Distortion')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to determine the optimal number of clusters\n",
    "determine_optimal_k(scaled_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d1c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Offer discounts based on cluster preferences\n",
    "for cluster_id in range(k):\n",
    "    cluster_data = data[data['Cluster'] == cluster_id]\n",
    "    # Implement personalized offers for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e1eb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the categorical feature\n",
    "categorical_feature = 'to_randomly_generated_account'\n",
    "\n",
    "# One-hot encode the selected categorical feature\n",
    "data_encoded = pd.get_dummies(data, columns=[categorical_feature], prefix=categorical_feature)\n",
    "\n",
    "# Combine numerical features with the one-hot encoded features\n",
    "X_combined = pd.concat([data[['from_totally_fake_account', 'monopoly_money_amount']], data_encoded.filter(regex=categorical_feature+'_')], axis=1)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_combined_scaled = scaler.fit_transform(X_combined)\n",
    "\n",
    "# Determine the optimal number of clusters (k)\n",
    "visualizer = KElbowVisualizer(KMeans(random_state=42), k=(2, 10))\n",
    "visualizer.fit(X_combined_scaled)\n",
    "k = visualizer.elbow_value_\n",
    "\n",
    "# Apply K-means clustering to the combined features\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "data['Cluster'] = kmeans.fit_predict(X_combined_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238382d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ea84e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bu23957\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:1013\u001b[0m, in \u001b[0;36m_tree_query_radius_parallel_helper\u001b[1;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1008\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Helper for the Parallel calls in RadiusNeighborsMixin.radius_neighbors.\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m \n\u001b[0;32m   1010\u001b[0m \u001b[38;5;124;03mThe Cython method tree.query_radius is not directly picklable by\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;124;03mcloudpickle under PyPy.\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mquery_radius(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32msklearn\\neighbors\\_binary_tree.pxi:1374\u001b[0m, in \u001b[0;36msklearn.neighbors._kd_tree.BinaryTree.query_radius\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msklearn\\neighbors\\_binary_tree.pxi:1327\u001b[0m, in \u001b[0;36msklearn.neighbors._kd_tree.BinaryTree.query_radius\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Perform DBSCAN clustering\u001b[39;00m\n\u001b[0;32m     25\u001b[0m dbscan \u001b[38;5;241m=\u001b[39m DBSCAN(eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m dbscan_labels \u001b[38;5;241m=\u001b[39m dbscan\u001b[38;5;241m.\u001b[39mfit_predict(X_scaled)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Perform Agglomerative Hierarchical Clustering\u001b[39;00m\n\u001b[0;32m     29\u001b[0m agg_clustering \u001b[38;5;241m=\u001b[39m AgglomerativeClustering(n_clusters\u001b[38;5;241m=\u001b[39mn_clusters)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_dbscan.py:448\u001b[0m, in \u001b[0;36mDBSCAN.fit_predict\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    424\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute clusters from a data or distance matrix and predict labels.\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \n\u001b[0;32m    426\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;124;03m        Cluster labels. Noisy samples are given the label -1.\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 448\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_dbscan.py:396\u001b[0m, in \u001b[0;36mDBSCAN.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    394\u001b[0m neighbors_model\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m    395\u001b[0m \u001b[38;5;66;03m# This has worst case O(n^2) memory complexity\u001b[39;00m\n\u001b[1;32m--> 396\u001b[0m neighborhoods \u001b[38;5;241m=\u001b[39m neighbors_model\u001b[38;5;241m.\u001b[39mradius_neighbors(X, return_distance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    399\u001b[0m     n_neighbors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mlen\u001b[39m(neighbors) \u001b[38;5;28;01mfor\u001b[39;00m neighbors \u001b[38;5;129;01min\u001b[39;00m neighborhoods])\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:1235\u001b[0m, in \u001b[0;36mRadiusNeighborsMixin.radius_neighbors\u001b[1;34m(self, X, radius, return_distance, sort_results)\u001b[0m\n\u001b[0;32m   1233\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m   1234\u001b[0m delayed_query \u001b[38;5;241m=\u001b[39m delayed(_tree_query_radius_parallel_helper)\n\u001b[1;32m-> 1235\u001b[0m chunked_results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs, prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m)(\n\u001b[0;32m   1236\u001b[0m     delayed_query(\n\u001b[0;32m   1237\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tree, X[s], radius, return_distance, sort_results\u001b[38;5;241m=\u001b[39msort_results\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[0;32m   1239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m gen_even_slices(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], n_jobs)\n\u001b[0;32m   1240\u001b[0m )\n\u001b[0;32m   1241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_distance:\n\u001b[0;32m   1242\u001b[0m     neigh_ind, neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mchunked_results))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:126\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    117\u001b[0m         (\n\u001b[0;32m    118\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sklearn.utils.parallel.delayed` should be used with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m    124\u001b[0m     )\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\contextlib.py:141\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, typ, value, traceback):\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('fake_transactional_data_24.csv')\n",
    "\n",
    "# Preprocessing: Select relevant features and scale the data\n",
    "X = data[['from_totally_fake_account', 'monopoly_money_amount']]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define the number of clusters for K-means\n",
    "n_clusters = 3\n",
    "\n",
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Perform DBSCAN clustering\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=10)\n",
    "dbscan_labels = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "# Perform Agglomerative Hierarchical Clustering\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "agg_labels = agg_clustering.fit_predict(X_scaled)\n",
    "\n",
    "# Evaluate clustering using silhouette score\n",
    "kmeans_silhouette = silhouette_score(X_scaled, kmeans_labels)\n",
    "dbscan_silhouette = silhouette_score(X_scaled, dbscan_labels)\n",
    "agg_silhouette = silhouette_score(X_scaled, agg_labels)\n",
    "\n",
    "print(f\"Silhouette Score (K-means): {kmeans_silhouette}\")\n",
    "print(f\"Silhouette Score (DBSCAN): {dbscan_silhouette}\")\n",
    "print(f\"Silhouette Score (Agglomerative): {agg_silhouette}\")\n",
    "\n",
    "# Visualize the clustering results\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.scatterplot(data=data, x='from_totally_fake_account', y='monopoly_money_amount', hue=kmeans_labels, palette='viridis')\n",
    "plt.title('K-means Clustering')\n",
    "plt.xlabel('From Totally Fake Account')\n",
    "plt.ylabel('Monopoly Money Amount')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.scatterplot(data=data, x='from_totally_fake_account', y='monopoly_money_amount', hue=dbscan_labels, palette='viridis')\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.xlabel('From Totally Fake Account')\n",
    "plt.ylabel('Monopoly Money Amount')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.scatterplot(data=data, x='from_totally_fake_account', y='monopoly_money_amount', hue=agg_labels, palette='viridis')\n",
    "plt.title('Agglomerative Clustering')\n",
    "plt.xlabel('From Totally Fake Account')\n",
    "plt.ylabel('Monopoly Money Amount')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09955e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b064e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
